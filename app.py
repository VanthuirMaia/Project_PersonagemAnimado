"""
Interface Streamlit - Personagem Generativo e Anima√ß√£o Curta
Pipeline completo de gera√ß√£o de personagens e v√≠deo animado

Institui√ß√£o: Universidade de Pernambuco (UPE)
Programa: Resid√™ncia em IA Generativa
Disciplina: IA Generativa para M√≠dia Visual
Autores: Vanthuir Maia e Rodrigo Santana
"""

import streamlit as st
import sys
from pathlib import Path
import json
from datetime import datetime
import shutil

# Adicionar diret√≥rio src ao path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from image_generator import ImageGenerator
from video_generator import VideoGenerator


# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Personagem Generativo e Anima√ß√£o",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded"
)


def init_session_state():
    """Inicializa vari√°veis de sess√£o"""
    if 'generated_images' not in st.session_state:
        st.session_state.generated_images = []
    if 'video_path' not in st.session_state:
        st.session_state.video_path = None
    if 'generation_params' not in st.session_state:
        st.session_state.generation_params = {}
    if 'video_params' not in st.session_state:
        st.session_state.video_params = {}


def main():
    """Fun√ß√£o principal da aplica√ß√£o"""
    init_session_state()

    # T√≠tulo
    st.title("üé® Personagem Generativo e Anima√ß√£o Curta")
    st.markdown("""
    ### Pipeline de IA Generativa para Cria√ß√£o de Personagens Animados
    Este sistema cria personagens visuais consistentes e gera uma anima√ß√£o curta em v√≠deo.

    ---
    **Institui√ß√£o**: Universidade de Pernambuco (UPE)
    **Programa**: Resid√™ncia em IA Generativa
    **Disciplina**: IA Generativa para M√≠dia Visual
    **Autores**: Vanthuir Maia e Rodrigo Santana
    """)

    # Sidebar - Configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")

        # Verificar dispositivo
        import torch
        has_cuda = torch.cuda.is_available()
        device_info = "üü¢ GPU CUDA" if has_cuda else "üî¥ CPU (Lento)"

        st.info(f"**Dispositivo**: {device_info}")
        if not has_cuda:
            st.warning("‚ö†Ô∏è Rodando em CPU. Gera√ß√£o ser√° MUITO lenta (~5-10 min por imagem). Veja OTIMIZACOES_CPU.md")

        st.subheader("Gera√ß√£o de Imagens")

        # Preset de configura√ß√µes
        preset = st.selectbox(
            "Preset de Velocidade",
            ["Ultra R√°pido (CPU)", "R√°pido", "Balanceado", "Alta Qualidade"],
            index=0 if not has_cuda else 2,
            help="Configura√ß√µes pr√©-definidas. Ultra R√°pido recomendado para CPU"
        )

        # Definir valores baseado no preset
        preset_configs = {
            "Ultra R√°pido (CPU)": {"images": 3, "steps": 20, "guidance": 7.0},
            "R√°pido": {"images": 5, "steps": 30, "guidance": 7.0},
            "Balanceado": {"images": 10, "steps": 50, "guidance": 7.5},
            "Alta Qualidade": {"images": 10, "steps": 80, "guidance": 8.0}
        }

        preset_config = preset_configs[preset]

        model_choice = st.selectbox(
            "Modelo",
            ["runwayml/stable-diffusion-v1-5", "stabilityai/stable-diffusion-2-1"],
            help="Escolha o modelo de gera√ß√£o de imagens"
        )

        num_images = st.slider(
            "N√∫mero de Imagens",
            min_value=1,
            max_value=20,
            value=preset_config["images"],
            help="Quantidade de imagens a gerar. CPU: recomendado 1-3 para teste"
        )

        seed = st.number_input(
            "Seed (0 = aleat√≥rio)",
            min_value=0,
            max_value=2**32-1,
            value=42,
            help="Seed para reprodutibilidade. Use 0 para seed aleat√≥rio"
        )

        guidance_scale = st.slider(
            "Guidance Scale",
            min_value=1.0,
            max_value=20.0,
            value=preset_config["guidance"],
            step=0.5,
            help="For√ßa de ader√™ncia ao prompt (7-15 recomendado)"
        )

        num_inference_steps = st.slider(
            "Passos de Infer√™ncia",
            min_value=10,
            max_value=100,
            value=preset_config["steps"],
            help="Mais passos = melhor qualidade (mas mais lento). CPU: use 20"
        )

        # Estimativa de tempo
        time_per_image_cpu = num_inference_steps * 0.15  # ~9 seg por step em CPU m√©dia
        time_per_image_gpu = num_inference_steps * 0.02  # ~1 seg por step em GPU m√©dia

        if has_cuda:
            estimated_time = (time_per_image_gpu * num_images) / 60
            st.info(f"‚è±Ô∏è Tempo estimado: ~{estimated_time:.1f} minutos")
        else:
            estimated_time = (time_per_image_cpu * num_images) / 60
            st.warning(f"‚è±Ô∏è Tempo estimado: ~{estimated_time:.0f} minutos")
            if estimated_time > 30:
                st.error(f"üö® Isso vai demorar MUITO! Reduza imagens ou steps.")

        st.divider()

        st.subheader("Gera√ß√£o de V√≠deo")
        fps = st.slider(
            "FPS (Frames por Segundo)",
            min_value=2,
            max_value=30,
            value=3,
            help="Velocidade do v√≠deo"
        )

        duration_per_image = st.slider(
            "Dura√ß√£o por Imagem (s)",
            min_value=0.5,
            max_value=3.0,
            value=1.5,
            step=0.1,
            help="Quanto tempo cada imagem aparece"
        )

        transition_frames = st.slider(
            "Frames de Transi√ß√£o",
            min_value=5,
            max_value=30,
            value=15,
            help="Suavidade da transi√ß√£o entre imagens"
        )

        add_loop = st.checkbox(
            "Adicionar Loop",
            value=True,
            help="Criar transi√ß√£o de volta para primeira imagem"
        )

    # √Årea principal
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìù Gera√ß√£o",
        "üñºÔ∏è Imagens",
        "üé¨ V√≠deo",
        "üìä Documenta√ß√£o"
    ])

    # Tab 1: Gera√ß√£o
    with tab1:
        st.header("Cria√ß√£o do Personagem")

        # Prompt do personagem
        st.subheader("Descri√ß√£o do Personagem")
        prompt = st.text_area(
            "Descreva seu personagem em detalhes",
            value=(
                "A cute cartoon robot character, round body, big expressive eyes, "
                "friendly smile, blue and white colors, simple design, "
                "mascot style, standing pose, white background, "
                "digital art, high quality, consistent character design"
            ),
            height=150,
            help="Seja espec√≠fico sobre apar√™ncia, estilo, cores, pose, etc."
        )

        negative_prompt = st.text_area(
            "Prompt Negativo (opcional)",
            value=(
                "blurry, low quality, distorted, deformed, ugly, "
                "bad anatomy, bad proportions, extra limbs, "
                "text, watermark, signature"
            ),
            height=100,
            help="O que voc√™ quer evitar nas imagens"
        )

        # Bot√£o de gera√ß√£o
        col1, col2 = st.columns([1, 3])
        with col1:
            generate_btn = st.button(
                "üé® Gerar Imagens",
                type="primary",
                use_container_width=True
            )

        if generate_btn:
            if not prompt.strip():
                st.error("Por favor, forne√ßa uma descri√ß√£o do personagem!")
            else:
                # Placeholder para progresso
                progress_bar = st.progress(0)
                status_text = st.empty()
                time_text = st.empty()

                try:
                    # Criar gerador
                    status_text.text("üîß Carregando modelo...")
                    generator = ImageGenerator(model_id=model_choice)

                    # Criar diret√≥rio √∫nico para esta gera√ß√£o
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_dir = f"outputs/images/{timestamp}"

                    # Fun√ß√£o de callback para atualizar progresso
                    def update_progress(current, total, status, time_remaining=0, time_per_image=0):
                        progress = current / total
                        progress_bar.progress(progress)

                        if status == "generating":
                            status_text.text(f"üé® Gerando imagem {current + 1}/{total}...")
                        elif status == "completed":
                            mins_remaining = int(time_remaining // 60)
                            secs_remaining = int(time_remaining % 60)

                            status_text.text(f"‚úÖ Imagem {current}/{total} conclu√≠da!")

                            if time_remaining > 0:
                                time_text.markdown(
                                    f"‚è±Ô∏è **Tempo m√©dio por imagem**: {time_per_image:.1f}s | "
                                    f"**Tempo restante estimado**: {mins_remaining}min {secs_remaining}s"
                                )
                            else:
                                time_text.markdown(f"üéâ **Todas as imagens geradas!**")

                    # Gerar imagens com callback
                    status_text.text(f"üöÄ Iniciando gera√ß√£o de {num_images} imagens...")

                    images = generator.generate_images(
                        prompt=prompt,
                        num_images=num_images,
                        negative_prompt=negative_prompt if negative_prompt.strip() else None,
                        seed=seed if seed > 0 else None,
                        guidance_scale=guidance_scale,
                        num_inference_steps=num_inference_steps,
                        output_dir=output_dir,
                        progress_callback=update_progress
                    )

                    # Salvar na sess√£o
                    st.session_state.generated_images = images
                    st.session_state.generation_params = generator.get_generation_params()
                    st.session_state.output_dir = output_dir

                    # Limpar mem√≥ria
                    generator.cleanup()

                    # Finalizar
                    progress_bar.progress(1.0)
                    status_text.empty()
                    time_text.empty()

                    st.success(f"‚úÖ {len(images)} imagens geradas com sucesso!")
                    st.info(f"üìÅ Imagens salvas em: {output_dir}")
                    st.balloons()

                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    time_text.empty()
                    st.error(f"‚ùå Erro ao gerar imagens: {str(e)}")
                    st.exception(e)

    # Tab 2: Visualiza√ß√£o de Imagens
    with tab2:
        st.header("Imagens Geradas")

        if st.session_state.generated_images:
            st.success(f"Total de imagens: {len(st.session_state.generated_images)}")

            # Exibir par√¢metros de gera√ß√£o
            with st.expander("üìã Par√¢metros de Gera√ß√£o"):
                params = st.session_state.generation_params
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**Prompt:** {params.get('prompt', 'N/A')}")
                    st.write(f"**Seed:** {params.get('seed', 'N/A')}")
                    st.write(f"**Guidance Scale:** {params.get('guidance_scale', 'N/A')}")
                with col2:
                    st.write(f"**Passos:** {params.get('num_inference_steps', 'N/A')}")
                    st.write(f"**Resolu√ß√£o:** {params.get('width', 'N/A')}x{params.get('height', 'N/A')}")
                    st.write(f"**Modelo:** {params.get('model_id', 'N/A')}")

            # Mostrar imagens em grade
            st.subheader("Galeria de Imagens")
            cols = st.columns(3)
            for idx, img in enumerate(st.session_state.generated_images):
                with cols[idx % 3]:
                    st.image(img, caption=f"Imagem {idx + 1}", use_container_width=True)

        else:
            st.info("Nenhuma imagem gerada ainda. V√° para a aba 'Gera√ß√£o' para criar seu personagem!")

    # Tab 3: Gera√ß√£o de V√≠deo
    with tab3:
        st.header("Gera√ß√£o de V√≠deo")

        if st.session_state.generated_images:
            st.success(f"Pronto para criar v√≠deo com {len(st.session_state.generated_images)} imagens")

            # Bot√£o de gera√ß√£o de v√≠deo
            col1, col2 = st.columns([1, 3])
            with col1:
                generate_video_btn = st.button(
                    "üé¨ Gerar V√≠deo",
                    type="primary",
                    use_container_width=True
                )

            if generate_video_btn:
                with st.spinner("Gerando v√≠deo... Aguarde."):
                    try:
                        # Criar gerador de v√≠deo
                        video_gen = VideoGenerator()

                        # Criar diret√≥rio de v√≠deo
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        video_output = f"outputs/videos/animation_{timestamp}.mp4"

                        # Gerar v√≠deo
                        video_path = video_gen.create_video_from_images(
                            images=st.session_state.generated_images,
                            output_path=video_output,
                            fps=fps,
                            duration_per_image=duration_per_image,
                            transition_frames=transition_frames,
                            add_loop=add_loop
                        )

                        # Salvar na sess√£o
                        st.session_state.video_path = video_path
                        st.session_state.video_params = video_gen.get_video_params()

                        st.success("‚úÖ V√≠deo gerado com sucesso!")

                    except Exception as e:
                        st.error(f"Erro ao gerar v√≠deo: {str(e)}")
                        st.exception(e)

            # Mostrar v√≠deo se dispon√≠vel
            if st.session_state.video_path:
                st.subheader("V√≠deo Gerado")

                # Exibir par√¢metros do v√≠deo
                with st.expander("üìã Par√¢metros do V√≠deo"):
                    vparams = st.session_state.video_params
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**N√∫mero de Imagens:** {vparams.get('num_images', 'N/A')}")
                        st.write(f"**FPS:** {vparams.get('fps', 'N/A')}")
                        st.write(f"**Dura√ß√£o por Imagem:** {vparams.get('duration_per_image', 'N/A')}s")
                    with col2:
                        st.write(f"**Frames de Transi√ß√£o:** {vparams.get('transition_frames', 'N/A')}")
                        st.write(f"**Dura√ß√£o Total:** {vparams.get('total_duration', 'N/A'):.2f}s")
                        st.write(f"**Resolu√ß√£o:** {vparams.get('resolution', 'N/A')}")

                # Reproduzir v√≠deo
                st.video(st.session_state.video_path)

                # Bot√£o de download
                with open(st.session_state.video_path, "rb") as file:
                    st.download_button(
                        label="‚¨áÔ∏è Download do V√≠deo",
                        data=file,
                        file_name=Path(st.session_state.video_path).name,
                        mime="video/mp4"
                    )

        else:
            st.info("Gere as imagens primeiro antes de criar o v√≠deo!")

    # Tab 4: Documenta√ß√£o
    with tab4:
        st.header("Documenta√ß√£o T√©cnica")

        st.markdown("""
        ## Pipeline de Gera√ß√£o

        ### 1. Gera√ß√£o de Imagens
        - **Modelo**: Stable Diffusion (Hugging Face Diffusers)
        - **T√©cnica**: Text-to-Image com controle de seed
        - **Estrat√©gia de Consist√™ncia**: Seeds sequenciais a partir de uma seed base
        - **Par√¢metros Principais**:
          - Guidance Scale: controla ader√™ncia ao prompt
          - Inference Steps: qualidade da gera√ß√£o
          - Negative Prompt: evita caracter√≠sticas indesejadas

        ### 2. Gera√ß√£o de V√≠deo
        - **T√©cnica**: Interpola√ß√£o linear entre frames (cross-dissolve)
        - **Biblioteca**: OpenCV
        - **Processo**:
          1. Cada imagem √© mantida por N frames (definido por FPS √ó dura√ß√£o)
          2. Transi√ß√µes suaves entre imagens usando cv2.addWeighted
          3. Loop opcional para criar anima√ß√£o cont√≠nua

        ### 3. Ferramentas Utilizadas
        - **diffusers**: Gera√ß√£o de imagens com Stable Diffusion
        - **transformers**: Modelos de linguagem para processamento de prompts
        - **torch**: Backend de deep learning
        - **opencv-python**: Processamento de v√≠deo
        - **streamlit**: Interface web interativa

        ### 4. Desafios e Solu√ß√µes

        #### Consist√™ncia Visual
        - **Desafio**: Manter identidade do personagem entre imagens
        - **Solu√ß√£o**: Uso de seeds sequenciais e prompt detalhado

        #### Coer√™ncia Temporal
        - **Desafio**: Transi√ß√µes suaves no v√≠deo
        - **Solu√ß√£o**: Interpola√ß√£o linear entre frames

        #### Limita√ß√µes
        - Modelos locais requerem GPU com boa mem√≥ria
        - Gera√ß√£o pode ser lenta em hardware limitado
        - Consist√™ncia n√£o √© perfeita (varia√ß√µes podem ocorrer)

        ### 5. Melhorias Futuras
        - Implementar ControlNet para maior controle
        - Adicionar motion transfer com MediaPipe
        - Integrar modelos text-to-video (Gen-2, Pika)
        - Adicionar efeitos de zoom, pan, rotate
        """)

        # Exportar documenta√ß√£o completa
        if st.session_state.generation_params and st.session_state.video_params:
            st.subheader("Exportar Documenta√ß√£o Completa")

            doc_data = {
                "projeto": "Personagem Generativo e Anima√ß√£o Curta",
                "timestamp": datetime.now().isoformat(),
                "gera√ß√£o_imagens": st.session_state.generation_params,
                "gera√ß√£o_v√≠deo": st.session_state.video_params,
                "pipeline": {
                    "etapa_1": "Gera√ß√£o de imagens com Stable Diffusion",
                    "etapa_2": "Cria√ß√£o de v√≠deo com interpola√ß√£o de frames",
                    "ferramentas": ["Stable Diffusion", "OpenCV", "Streamlit"],
                }
            }

            doc_json = json.dumps(doc_data, indent=2, ensure_ascii=False)

            st.download_button(
                label="üìÑ Download Documenta√ß√£o (JSON)",
                data=doc_json,
                file_name=f"documentacao_tecnica_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )


if __name__ == "__main__":
    main()
