"""
Interface Streamlit - Personagem Generativo e Anima√ß√£o Curta
Pipeline completo de gera√ß√£o de personagens e v√≠deo animado

Institui√ß√£o: Universidade de Pernambuco (UPE)
Programa: Resid√™ncia em IA Generativa
Disciplina: IA Generativa para M√≠dia Visual
Autores: Vanthuir Maia e Rodrigo Santana
"""

import streamlit as st
import sys
from pathlib import Path
import json
from datetime import datetime
import shutil
import time
import os

# Importar torch normalmente (sem tentar limpar/reimportar)
try:
    import torch
    print(f"[INIT] PyTorch importado: {torch.__version__}")
    print(f"[INIT] PyTorch localiza√ß√£o: {torch.__file__}")
    print(f"[INIT] Python execut√°vel: {sys.executable}")
    print(f"[INIT] torch.cuda.is_available(): {torch.cuda.is_available()}")
    
    # Verificar se √© vers√£o CPU-only
    if '+cpu' in torch.__version__:
        print(f"[INIT] ‚ö†Ô∏è AVISO: PyTorch CPU-only detectado ({torch.__version__})")
        print(f"[INIT] ‚ö†Ô∏è Instale PyTorch com CUDA: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
    
    if torch.cuda.is_available():
        try:
            gpu_name = torch.cuda.get_device_name(0)
            cuda_version = torch.version.cuda
            print(f"[INIT] ‚úÖ CUDA detectado: {gpu_name}")
            print(f"[INIT] ‚úÖ CUDA version: {cuda_version}")
            
            # Testar cria√ß√£o de tensor
            test_tensor = torch.zeros(1).cuda()
            print(f"[INIT] ‚úÖ Tensor de teste criado na GPU: {test_tensor.device}")
            del test_tensor
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"[INIT] ‚ö†Ô∏è CUDA dispon√≠vel mas erro ao usar: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"[INIT] ‚ùå CUDA n√£o dispon√≠vel")
        print(f"[INIT] Verificando vari√°veis de ambiente...")
        cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', 'N/A')
        print(f"[INIT] CUDA_VISIBLE_DEVICES: {cuda_visible}")
        print(f"[INIT] PATH cont√©m CUDA: {'cuda' in os.environ.get('PATH', '').lower()}")
        
except Exception as e:
    print(f"[INIT] ‚ùå Erro ao importar/verificar torch: {e}")
    import traceback
    traceback.print_exc()
    # Definir torch como None para evitar erros posteriores
    torch = None

# Adicionar diret√≥rio src ao path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

# Importa√ß√µes com tratamento de erro mais claro
try:
    from image_generator import ImageGenerator
    from video_generator import VideoGenerator
except ImportError as e:
    st.error(f"‚ùå Erro ao importar m√≥dulos: {str(e)}")
    st.error("‚ö†Ô∏è Verifique se todas as depend√™ncias est√£o instaladas corretamente.")
    st.error("üí° Execute: pip install -r requirements.txt")
    st.stop()


# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Personagem Generativo e Anima√ß√£o",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded"
)


def init_session_state():
    """Inicializa vari√°veis de sess√£o"""
    if 'generated_images' not in st.session_state:
        st.session_state.generated_images = []
    if 'video_path' not in st.session_state:
        st.session_state.video_path = None
    if 'generation_params' not in st.session_state:
        st.session_state.generation_params = {}
    if 'video_params' not in st.session_state:
        st.session_state.video_params = {}
    # Inicializar vari√°veis de v√≠deo
    if 'use_svd' not in st.session_state:
        st.session_state.use_svd = False
    if 'fps' not in st.session_state:
        st.session_state.fps = 3
    if 'duration_per_image' not in st.session_state:
        st.session_state.duration_per_image = 1.5
    if 'transition_frames' not in st.session_state:
        st.session_state.transition_frames = 15
    if 'add_loop' not in st.session_state:
        st.session_state.add_loop = True
    if 'svd_frames' not in st.session_state:
        st.session_state.svd_frames = 20  # Padr√£o: 20 frames
    if 'svd_fps' not in st.session_state:
        st.session_state.svd_fps = 4  # Padr√£o: 4 fps = 5 segundos com 20 frames


def main():
    """Fun√ß√£o principal da aplica√ß√£o"""
    init_session_state()

    # T√≠tulo
    st.title("üé® Personagem Generativo e Anima√ß√£o Curta")
    st.markdown("""
    ### Pipeline de IA Generativa para Cria√ß√£o de Personagens Animados
    Este sistema cria personagens visuais consistentes e gera uma anima√ß√£o curta em v√≠deo.

    ---
    **Institui√ß√£o**: Universidade de Pernambuco (UPE)
    **Programa**: Resid√™ncia em IA Generativa
    **Disciplina**: IA Generativa para M√≠dia Visual
    **Autores**: Vanthuir Maia e Rodrigo Santana
    """)

    # Sidebar - Configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")

        # Verificar dispositivo com verifica√ß√£o robusta
        # torch j√° foi importado no topo do arquivo
        
        # For√ßar detec√ß√£o de CUDA
        has_cuda = False
        cuda_error = None
        
        try:
            # Verificar se CUDA est√° dispon√≠vel
            if torch.cuda.is_available():
                # Tentar criar tensor na GPU para confirmar
                test_tensor = torch.zeros(1).cuda()
                del test_tensor
                torch.cuda.empty_cache()
                has_cuda = True
                gpu_name = torch.cuda.get_device_name(0)
                device_info = f"üü¢ GPU CUDA ({gpu_name})"
            else:
                device_info = "üî¥ CPU (Lento)"
        except Exception as e:
            cuda_error = str(e)
            device_info = "üî¥ CPU (Lento)"
            has_cuda = False

        st.info(f"**Dispositivo**: {device_info}")
        if has_cuda:
            st.success(f"‚úÖ GPU detectada e funcionando!")
        else:
            st.warning("‚ö†Ô∏è Rodando em CPU. Gera√ß√£o ser√° MUITO lenta (~5-10 min por imagem). Veja OTIMIZACOES_CPU.md")
            if cuda_error:
                with st.expander("üîç Detalhes do erro CUDA"):
                    st.code(cuda_error)

        st.subheader("Gera√ß√£o de Imagens")

        # Preset de configura√ß√µes
        preset = st.selectbox(
            "Preset de Velocidade",
            ["Ultra R√°pido (CPU)", "R√°pido", "Balanceado", "Alta Qualidade"],
            index=0 if not has_cuda else 2,
            help="Configura√ß√µes pr√©-definidas. Ultra R√°pido recomendado para CPU"
        )

        # Definir valores baseado no preset
        preset_configs = {
            "Ultra R√°pido (CPU)": {"images": 3, "steps": 20, "guidance": 7.0},
            "R√°pido": {"images": 5, "steps": 30, "guidance": 7.0},
            "Balanceado": {"images": 10, "steps": 50, "guidance": 7.5},
            "Alta Qualidade": {"images": 10, "steps": 80, "guidance": 8.0}
        }

        preset_config = preset_configs[preset]

        model_choice = st.selectbox(
            "Modelo",
            ["runwayml/stable-diffusion-v1-5", "stabilityai/stable-diffusion-2-1"],
            help="Escolha o modelo de gera√ß√£o de imagens"
        )

        num_images = st.slider(
            "N√∫mero de Imagens",
            min_value=1,
            max_value=20,
            value=preset_config["images"],
            help="Quantidade de imagens a gerar. CPU: recomendado 1-3 para teste"
        )

        seed = st.number_input(
            "Seed (0 = aleat√≥rio)",
            min_value=0,
            max_value=2**32-1,
            value=42,
            help="Seed para reprodutibilidade. Use 0 para seed aleat√≥rio"
        )

        guidance_scale = st.slider(
            "Guidance Scale",
            min_value=1.0,
            max_value=20.0,
            value=preset_config["guidance"],
            step=0.5,
            help="For√ßa de ader√™ncia ao prompt (7-15 recomendado)"
        )

        num_inference_steps = st.slider(
            "Passos de Infer√™ncia",
            min_value=10,
            max_value=100,
            value=preset_config["steps"],
            help="Mais passos = melhor qualidade (mas mais lento). CPU: use 20"
        )

        # Estimativa de tempo
        time_per_image_cpu = num_inference_steps * 0.15  # ~9 seg por step em CPU m√©dia
        time_per_image_gpu = num_inference_steps * 0.02  # ~1 seg por step em GPU m√©dia

        if has_cuda:
            estimated_time = (time_per_image_gpu * num_images) / 60
            st.info(f"‚è±Ô∏è Tempo estimado: ~{estimated_time:.1f} minutos")
        else:
            estimated_time = (time_per_image_cpu * num_images) / 60
            st.warning(f"‚è±Ô∏è Tempo estimado: ~{estimated_time:.0f} minutos")
            if estimated_time > 30:
                st.error(f"üö® Isso vai demorar MUITO! Reduza imagens ou steps.")

        st.divider()

        st.subheader("Gera√ß√£o de V√≠deo")
        
        # Sele√ß√£o de m√©todo de anima√ß√£o
        animation_method = st.selectbox(
            "M√©todo de Anima√ß√£o",
            ["Transi√ß√µes (OpenCV)", "IA - Stable Video Diffusion"],
            help="Transi√ß√µes: combina m√∫ltiplas imagens. SVD: anima imagem individual com IA (requer GPU)"
        )
        
        use_svd = animation_method == "IA - Stable Video Diffusion"
        
        # Salvar no session_state para usar na tab 3
        st.session_state.use_svd = use_svd
        
        if use_svd:
            # Configura√ß√µes espec√≠ficas do SVD
            st.info("üé® **Stable Video Diffusion**: Anima uma imagem individual com movimento realista (requer GPU)")
            
            svd_resolution = st.selectbox(
                "Resolu√ß√£o",
                ["512x320 (Recomendado 8GB)", "384x256 (Ultra-Econ√¥mico)", "640x384 (Avan√ßado)"],
                index=0,
                help="Resolu√ß√£o menor = menos mem√≥ria GPU"
            )
            
            # Converter sele√ß√£o para tupla
            resolution_map = {
                "512x320 (Recomendado 8GB)": (512, 320),
                "384x256 (Ultra-Econ√¥mico)": (384, 256),
                "640x384 (Avan√ßado)": (640, 384)
            }
            svd_res = resolution_map[svd_resolution]
            
            svd_frames = st.slider(
                "Frames do V√≠deo",
                min_value=15,
                max_value=25,
                value=20,
                help="Mais frames = mais mem√≥ria. 20-25 frames = 5-10s de v√≠deo"
            )
            
            svd_fps = st.slider(
                "FPS do V√≠deo",
                min_value=3,
                max_value=7,
                value=4,
                help="Frames por segundo. Menor FPS = v√≠deo mais longo"
            )
            
            # Calcular e mostrar dura√ß√£o estimada
            video_duration = svd_frames / svd_fps
            duration_color = "üü¢" if 5 <= video_duration <= 10 else "üü°"
            st.info(f"{duration_color} **Dura√ß√£o estimada**: ~{video_duration:.1f} segundos ({svd_frames} frames √∑ {svd_fps} fps)")
            
            svd_steps = st.slider(
                "Passos de Infer√™ncia",
                min_value=20,
                max_value=30,
                value=25,
                help="Mais passos = melhor qualidade (mais lento)"
            )
            
            if has_cuda:
                estimated_svd_time = (svd_steps * 0.05 * svd_frames) / 60  # Estimativa
                st.info(f"‚è±Ô∏è Tempo estimado: ~{estimated_svd_time:.1f} minutos")
            else:
                st.error("‚ö†Ô∏è SVD requer GPU CUDA. Use 'Transi√ß√µes (OpenCV)' em vez disso.")
            
            # Salvar par√¢metros SVD no session_state
            st.session_state.svd_frames = svd_frames
            st.session_state.svd_fps = svd_fps
            st.session_state.svd_res = svd_res
            st.session_state.svd_steps = svd_steps
            
            # Inicializar vari√°veis OpenCV como None quando usando SVD
            fps = None
            duration_per_image = None
            transition_frames = None
            add_loop = None
                
        else:
            # Configura√ß√µes tradicionais (OpenCV)
            fps = st.slider(
                "FPS (Frames por Segundo)",
                min_value=2,
                max_value=30,
                value=3,
                help="Velocidade do v√≠deo"
            )

            duration_per_image = st.slider(
                "Dura√ß√£o por Imagem (s)",
                min_value=0.5,
                max_value=3.0,
                value=1.5,
                step=0.1,
                help="Quanto tempo cada imagem aparece"
            )

            transition_frames = st.slider(
                "Frames de Transi√ß√£o",
                min_value=5,
                max_value=30,
                value=15,
                help="Suavidade da transi√ß√£o entre imagens"
            )

            add_loop = st.checkbox(
                "Adicionar Loop",
                value=True,
                help="Criar transi√ß√£o de volta para primeira imagem"
            )
            
            # Salvar par√¢metros OpenCV no session_state
            st.session_state.fps = fps
            st.session_state.duration_per_image = duration_per_image
            st.session_state.transition_frames = transition_frames
            st.session_state.add_loop = add_loop
            
            # Inicializar vari√°veis SVD como None quando usando OpenCV
            svd_frames = None
            svd_fps = None
            svd_res = None
            svd_steps = None

    # √Årea principal
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìù Gera√ß√£o",
        "üñºÔ∏è Imagens",
        "üé¨ V√≠deo",
        "üìä Documenta√ß√£o"
    ])

    # Tab 1: Gera√ß√£o
    with tab1:
        st.header("Cria√ß√£o do Personagem")

        # Prompt do personagem
        st.subheader("Descri√ß√£o do Personagem")
        prompt = st.text_area(
            "Descreva seu personagem em detalhes",
            value=(
                "A cute cartoon robot character, round body, big expressive eyes, "
                "friendly smile, blue and white colors, simple design, "
                "mascot style, standing pose, white background, "
                "digital art, high quality, consistent character design"
            ),
            height=150,
            help="Seja espec√≠fico sobre apar√™ncia, estilo, cores, pose, etc."
        )

        negative_prompt = st.text_area(
            "Prompt Negativo (opcional)",
            value=(
                "blurry, low quality, distorted, deformed, ugly, "
                "bad anatomy, bad proportions, extra limbs, "
                "text, watermark, signature"
            ),
            height=100,
            help="O que voc√™ quer evitar nas imagens"
        )

        # Bot√£o de gera√ß√£o
        col1, col2 = st.columns([1, 3])
        with col1:
            generate_btn = st.button(
                "üé® Gerar Imagens",
                type="primary",
                width='stretch'
            )

        if generate_btn:
            if not prompt.strip():
                st.error("Por favor, forne√ßa uma descri√ß√£o do personagem!")
            else:
                # Placeholder para progresso
                progress_bar = st.progress(0)
                status_text = st.empty()
                time_text = st.empty()
                timer_container = st.empty()

                # Iniciar contador de tempo
                start_time = time.time()
                elapsed_time = 0

                try:
                    # Criar gerador
                    status_text.text("üîß Carregando modelo...")
                    load_start = time.time()
                    # For√ßar uso de CUDA se dispon√≠vel com verifica√ß√£o robusta
                    # torch j√° foi importado no topo do arquivo
                    device_param = "auto"  # Deixar ImageGenerator detectar automaticamente
                    try:
                        # Verificar CUDA de forma robusta (se torch estiver dispon√≠vel)
                        if torch is not None and torch.cuda.is_available():
                            # Testar se CUDA realmente funciona
                            test = torch.zeros(1).cuda()
                            del test
                            torch.cuda.empty_cache()
                            device_param = "cuda"
                            status_text.text(f"üîß Carregando modelo na GPU...")
                        else:
                            device_param = "cpu"
                            status_text.text(f"üîß Carregando modelo na CPU...")
                    except Exception as e:
                        device_param = "cpu"
                        status_text.text(f"üîß CUDA n√£o dispon√≠vel, usando CPU...")
                    
                    generator = ImageGenerator(model_id=model_choice, device=device_param)
                    load_time = time.time() - load_start
                    
                    timer_container.info(f"‚è±Ô∏è **Tempo de carregamento do modelo**: {load_time:.1f} segundos")

                    # Criar diret√≥rio √∫nico para esta gera√ß√£o
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_dir = f"outputs/images/{timestamp}"

                    # Fun√ß√£o de callback para atualizar progresso
                    def update_progress(current, total, status, time_remaining=0, time_per_image=0):
                        nonlocal elapsed_time
                        
                        progress = current / total
                        progress_bar.progress(progress)
                        
                        # Calcular tempo decorrido total
                        elapsed_time = time.time() - start_time
                        elapsed_mins = int(elapsed_time // 60)
                        elapsed_secs = int(elapsed_time % 60)

                        if status == "generating":
                            status_text.text(f"üé® Gerando imagem {current + 1}/{total}...")
                            
                            # Mostrar tempo decorrido
                            timer_container.markdown(
                                f"""
                                <div style='background-color: #f0f2f6; padding: 15px; border-radius: 10px; border-left: 5px solid #1f77b4;'>
                                    <h4 style='margin: 0; color: #1f77b4;'>‚è±Ô∏è Contador de Tempo</h4>
                                    <p style='margin: 5px 0;'><strong>Tempo decorrido:</strong> {elapsed_mins}min {elapsed_secs}s</p>
                                    <p style='margin: 5px 0;'><strong>Imagem atual:</strong> {current + 1}/{total}</p>
                                </div>
                                """,
                                unsafe_allow_html=True
                            )
                            
                        elif status == "completed":
                            status_text.text(f"‚úÖ Imagem {current}/{total} conclu√≠da!")
                            
                            if time_remaining > 0:
                                mins_remaining = int(time_remaining // 60)
                                secs_remaining = int(time_remaining % 60)
                                
                                # Calcular tempo total estimado
                                total_estimated = elapsed_time + time_remaining
                                total_mins = int(total_estimated // 60)
                                total_secs = int(total_estimated % 60)

                                time_text.markdown(
                                    f"‚è±Ô∏è **Tempo m√©dio por imagem**: {time_per_image:.1f}s"
                                )
                                
                                timer_container.markdown(
                                    f"""
                                    <div style='background-color: #e8f5e9; padding: 15px; border-radius: 10px; border-left: 5px solid #4caf50;'>
                                        <h4 style='margin: 0; color: #2e7d32;'>‚è±Ô∏è Contador de Tempo</h4>
                                        <p style='margin: 5px 0;'><strong>‚è≥ Tempo decorrido:</strong> {elapsed_mins}min {elapsed_secs}s</p>
                                        <p style='margin: 5px 0;'><strong>üìä Tempo por imagem:</strong> {time_per_image:.1f}s</p>
                                        <p style='margin: 5px 0;'><strong>‚è∞ Tempo restante estimado:</strong> {mins_remaining}min {secs_remaining}s</p>
                                        <p style='margin: 5px 0;'><strong>üéØ Tempo total estimado:</strong> {total_mins}min {total_secs}s</p>
                                        <p style='margin: 5px 0;'><strong>üìà Progresso:</strong> {current}/{total} imagens ({progress*100:.1f}%)</p>
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                            else:
                                # Finaliza√ß√£o
                                total_mins = int(elapsed_time // 60)
                                total_secs = int(elapsed_time % 60)
                                avg_time = elapsed_time / total if total > 0 else 0
                                
                                timer_container.markdown(
                                    f"""
                                    <div style='background-color: #fff3e0; padding: 15px; border-radius: 10px; border-left: 5px solid #ff9800;'>
                                        <h4 style='margin: 0; color: #e65100;'>üéâ Processamento Conclu√≠do!</h4>
                                        <p style='margin: 5px 0;'><strong>‚è±Ô∏è Tempo total:</strong> {total_mins}min {total_secs}s</p>
                                        <p style='margin: 5px 0;'><strong>üìä Tempo m√©dio por imagem:</strong> {avg_time:.1f}s</p>
                                        <p style='margin: 5px 0;'><strong>‚úÖ Total de imagens:</strong> {total}</p>
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )

                    # Gerar imagens com callback
                    status_text.text(f"üöÄ Iniciando gera√ß√£o de {num_images} imagens...")

                    images = generator.generate_images(
                        prompt=prompt,
                        num_images=num_images,
                        negative_prompt=negative_prompt if negative_prompt.strip() else None,
                        seed=seed if seed > 0 else None,
                        guidance_scale=guidance_scale,
                        num_inference_steps=num_inference_steps,
                        output_dir=output_dir,
                        progress_callback=update_progress
                    )

                    # Salvar na sess√£o
                    st.session_state.generated_images = images
                    st.session_state.generation_params = generator.get_generation_params()
                    st.session_state.output_dir = output_dir

                    # Limpar mem√≥ria
                    generator.cleanup()

                    # Calcular tempo total final
                    total_time = time.time() - start_time
                    total_mins = int(total_time // 60)
                    total_secs = int(total_time % 60)
                    avg_time = total_time / num_images if num_images > 0 else 0

                    # Finalizar
                    progress_bar.progress(1.0)
                    status_text.empty()
                    time_text.empty()

                    # Mostrar resumo final
                    st.success(f"‚úÖ {len(images)} imagens geradas com sucesso!")
                    st.info(f"üìÅ Imagens salvas em: {output_dir}")
                    
                    # Exibir resumo de tempo final
                    timer_container.markdown(
                        f"""
                        <div style='background-color: #e3f2fd; padding: 20px; border-radius: 10px; border-left: 5px solid #2196f3; margin-top: 20px;'>
                            <h3 style='margin: 0 0 15px 0; color: #1976d2;'>üìä Resumo do Processamento</h3>
                            <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px;'>
                                <div>
                                    <p style='margin: 5px 0; font-size: 16px;'><strong>‚è±Ô∏è Tempo Total:</strong></p>
                                    <p style='margin: 0; font-size: 24px; color: #1976d2; font-weight: bold;'>{total_mins}min {total_secs}s</p>
                                </div>
                                <div>
                                    <p style='margin: 5px 0; font-size: 16px;'><strong>üìä Tempo M√©dio/Imagem:</strong></p>
                                    <p style='margin: 0; font-size: 24px; color: #1976d2; font-weight: bold;'>{avg_time:.1f}s</p>
                                </div>
                                <div>
                                    <p style='margin: 5px 0; font-size: 16px;'><strong>üîß Tempo de Carregamento:</strong></p>
                                    <p style='margin: 0; font-size: 20px; color: #1976d2;'>{load_time:.1f}s</p>
                                </div>
                                <div>
                                    <p style='margin: 5px 0; font-size: 16px;'><strong>üé® Tempo de Gera√ß√£o:</strong></p>
                                    <p style='margin: 0; font-size: 20px; color: #1976d2;'>{total_time - load_time:.1f}s</p>
                                </div>
                            </div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    st.balloons()

                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    time_text.empty()
                    timer_container.empty()
                    
                    # Calcular tempo at√© o erro
                    error_time = time.time() - start_time
                    error_mins = int(error_time // 60)
                    error_secs = int(error_time % 60)
                    
                    st.error(f"‚ùå Erro ao gerar imagens: {str(e)}")
                    st.warning(f"‚è±Ô∏è Processamento interrompido ap√≥s {error_mins}min {error_secs}s")
                    st.exception(e)

    # Tab 2: Visualiza√ß√£o de Imagens
    with tab2:
        st.header("Imagens Geradas")

        if st.session_state.generated_images:
            st.success(f"Total de imagens: {len(st.session_state.generated_images)}")

            # Exibir par√¢metros de gera√ß√£o
            with st.expander("üìã Par√¢metros de Gera√ß√£o"):
                params = st.session_state.generation_params
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**Prompt:** {params.get('prompt', 'N/A')}")
                    st.write(f"**Seed:** {params.get('seed', 'N/A')}")
                    st.write(f"**Guidance Scale:** {params.get('guidance_scale', 'N/A')}")
                with col2:
                    st.write(f"**Passos:** {params.get('num_inference_steps', 'N/A')}")
                    st.write(f"**Resolu√ß√£o:** {params.get('width', 'N/A')}x{params.get('height', 'N/A')}")
                    st.write(f"**Modelo:** {params.get('model_id', 'N/A')}")

            # Mostrar imagens em grade
            st.subheader("Galeria de Imagens")
            cols = st.columns(3)
            for idx, img in enumerate(st.session_state.generated_images):
                with cols[idx % 3]:
                    st.image(img, caption=f"Imagem {idx + 1}", width='stretch')

        else:
            st.info("Nenhuma imagem gerada ainda. V√° para a aba 'Gera√ß√£o' para criar seu personagem!")

    # Tab 3: Gera√ß√£o de V√≠deo
    with tab3:
        st.header("Gera√ß√£o de V√≠deo")

        if st.session_state.generated_images:
            st.success(f"Pronto para criar v√≠deo com {len(st.session_state.generated_images)} imagens")

            # Verificar se est√° usando SVD (anima uma imagem por vez)
            use_svd = st.session_state.get('use_svd', False)
            
            # Seletor de imagem para SVD
            selected_image_idx = 0
            if use_svd and len(st.session_state.generated_images) > 1:
                st.subheader("üì∏ Escolher Imagem para Animar")
                st.info("üí° SVD anima uma imagem por vez. Escolha qual imagem deseja animar:")
                
                # Criar colunas para mostrar miniaturas
                num_cols = min(4, len(st.session_state.generated_images))
                cols = st.columns(num_cols)
                
                # Criar op√ß√µes para o selectbox
                image_options = []
                for i, img in enumerate(st.session_state.generated_images):
                    image_options.append(f"Imagem {i+1}")
                
                # Selectbox para escolher a imagem
                selected_option = st.selectbox(
                    "Selecione a imagem:",
                    options=image_options,
                    index=0,
                    help="Escolha qual imagem ser√° animada pelo Stable Video Diffusion"
                )
                
                # Extrair √≠ndice da op√ß√£o selecionada
                selected_image_idx = image_options.index(selected_option)
                
                # Mostrar preview da imagem selecionada
                st.image(
                    st.session_state.generated_images[selected_image_idx],
                    caption=f"Imagem selecionada: {selected_option}",
                    width=300
                )
            elif use_svd:
                # Se s√≥ tem uma imagem, usar ela
                selected_image_idx = 0
                st.info("üí° SVD anima uma imagem por vez. Usando a √∫nica imagem dispon√≠vel.")
                st.image(
                    st.session_state.generated_images[0],
                    caption="Imagem que ser√° animada",
                    width=300
                )

            # Bot√£o de gera√ß√£o de v√≠deo
            col1, col2 = st.columns([1, 3])
            with col1:
                generate_video_btn = st.button(
                    "üé¨ Gerar V√≠deo",
                    type="primary",
                    width='stretch'
                )

            if generate_video_btn:
                # Recuperar m√©todo do session_state
                use_svd = st.session_state.get('use_svd', False)
                
                if use_svd:
                    # M√©todo SVD - Animar imagem individual
                    if not has_cuda:
                        st.error("‚ùå Stable Video Diffusion requer GPU CUDA. Selecione 'Transi√ß√µes (OpenCV)' ou instale PyTorch com CUDA.")
                    else:
                        with st.spinner("üé® Gerando v√≠deo com IA (Stable Video Diffusion)... Isso pode levar algumas minutos/horas."):
                            try:
                                # Recuperar par√¢metros do session_state
                                svd_frames = st.session_state.get('svd_frames', 20)
                                svd_fps = st.session_state.get('svd_fps', 4)
                                svd_res = st.session_state.get('svd_res', (512, 320))
                                svd_steps = st.session_state.get('svd_steps', 25)
                                
                                # Criar gerador de v√≠deo
                                video_gen = VideoGenerator()

                                # Criar diret√≥rio de v√≠deo
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                video_output = f"outputs/videos/svd_animation_{timestamp}.mp4"

                                # Usar imagem selecionada (ou primeira se n√£o foi selecionada)
                                image_to_animate = st.session_state.generated_images[selected_image_idx]
                                
                                st.info(f"üé® Animando Imagem {selected_image_idx + 1} de {len(st.session_state.generated_images)} dispon√≠veis.")

                                # Gerar v√≠deo com SVD
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                # Callback para atualizar progresso
                                def update_progress(progress, status_msg):
                                    progress_bar.progress(progress)
                                    status_text.text(status_msg)
                                
                                # Inicializar com progresso de download
                                status_text.text("üîß Preparando modelo SVD...")
                                progress_bar.progress(0.05)
                                
                                video_path = video_gen.animate_image_svd(
                                    image=image_to_animate,
                                    output_path=video_output,
                                    num_frames=svd_frames,
                                    fps=svd_fps,
                                    resolution=svd_res,
                                    num_inference_steps=svd_steps,
                                    decode_chunk_size=1,
                                    progress_callback=update_progress
                                )
                                
                                progress_bar.progress(1.0)
                                status_text.text("‚úÖ V√≠deo gerado com sucesso!")

                                # Salvar na sess√£o
                                st.session_state.video_path = video_path
                                st.session_state.video_params = video_gen.get_video_params()

                                st.success("‚úÖ V√≠deo gerado com sucesso usando Stable Video Diffusion!")
                                
                                # Limpar mem√≥ria
                                video_gen.cleanup_svd()

                            except RuntimeError as e:
                                error_msg = str(e)
                                if "Out of Memory" in error_msg or "OOM" in error_msg:
                                    st.error("‚ùå Mem√≥ria GPU insuficiente!")
                                    st.warning("üí° Tente:")
                                    st.write("- Reduzir resolu√ß√£o para '384x256'")
                                    st.write("- Reduzir frames para 10")
                                    st.write("- Fechar outros programas usando GPU")
                                    st.write("- Ou use 'Transi√ß√µes (OpenCV)' que n√£o requer GPU")
                                else:
                                    st.error(f"Erro ao gerar v√≠deo: {error_msg}")
                                    st.exception(e)
                            except Exception as e:
                                st.error(f"Erro ao gerar v√≠deo: {str(e)}")
                                st.exception(e)
                            finally:
                                progress_bar.empty()
                                status_text.empty()
                else:
                    # M√©todo tradicional (OpenCV)
                    # Recuperar par√¢metros do session_state
                    fps = st.session_state.get('fps', 3)
                    duration_per_image = st.session_state.get('duration_per_image', 1.5)
                    transition_frames = st.session_state.get('transition_frames', 15)
                    add_loop = st.session_state.get('add_loop', True)
                    
                    if fps is None:
                        st.error("‚ö†Ô∏è Erro: Configura√ß√µes de v√≠deo n√£o encontradas. Configure na sidebar primeiro.")
                    else:
                        with st.spinner("Gerando v√≠deo... Aguarde."):
                            try:
                                # Criar gerador de v√≠deo
                                video_gen = VideoGenerator()

                                # Criar diret√≥rio de v√≠deo
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                video_output = f"outputs/videos/animation_{timestamp}.mp4"

                                # Gerar v√≠deo
                                video_path = video_gen.create_video_from_images(
                                    images=st.session_state.generated_images,
                                    output_path=video_output,
                                    fps=fps,
                                    duration_per_image=duration_per_image,
                                    transition_frames=transition_frames,
                                    add_loop=add_loop
                                )

                                # Salvar na sess√£o
                                st.session_state.video_path = video_path
                                st.session_state.video_params = video_gen.get_video_params()

                                st.success("‚úÖ V√≠deo gerado com sucesso!")

                            except Exception as e:
                                st.error(f"Erro ao gerar v√≠deo: {str(e)}")
                                st.exception(e)

            # Mostrar v√≠deo se dispon√≠vel
            if st.session_state.video_path:
                st.subheader("V√≠deo Gerado")

                # Exibir par√¢metros do v√≠deo
                with st.expander("üìã Par√¢metros do V√≠deo"):
                    vparams = st.session_state.video_params
                    method = vparams.get('method', 'opencv')
                    
                    if method == 'stable_video_diffusion':
                        # Par√¢metros SVD
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**M√©todo:** üé® Stable Video Diffusion (IA)")
                            st.write(f"**Frames:** {vparams.get('num_frames', 'N/A')}")
                            st.write(f"**FPS:** {vparams.get('fps', 'N/A')}")
                            st.write(f"**Resolu√ß√£o:** {vparams.get('resolution', 'N/A')}")
                        with col2:
                            st.write(f"**Resolu√ß√£o Original:** {vparams.get('original_resolution', 'N/A')}")
                            st.write(f"**Passos:** {vparams.get('num_inference_steps', 'N/A')}")
                            st.write(f"**Dura√ß√£o:** ~{vparams.get('duration', 'N/A'):.2f}s")
                            st.write(f"**Mem√≥ria GPU:** {vparams.get('gpu_memory_used', 'N/A')}")
                    else:
                        # Par√¢metros OpenCV tradicional
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**M√©todo:** üé¨ Transi√ß√µes (OpenCV)")
                            st.write(f"**N√∫mero de Imagens:** {vparams.get('num_images', 'N/A')}")
                            st.write(f"**FPS:** {vparams.get('fps', 'N/A')}")
                            st.write(f"**Dura√ß√£o por Imagem:** {vparams.get('duration_per_image', 'N/A')}s")
                        with col2:
                            st.write(f"**Frames de Transi√ß√£o:** {vparams.get('transition_frames', 'N/A')}")
                            st.write(f"**Dura√ß√£o Total:** {vparams.get('total_duration', 'N/A'):.2f}s")
                            st.write(f"**Resolu√ß√£o:** {vparams.get('resolution', 'N/A')}")
                            st.write(f"**Loop:** {'Sim' if vparams.get('add_loop', False) else 'N√£o'}")

                # Reproduzir v√≠deo
                st.video(st.session_state.video_path)

                # Bot√£o de download
                with open(st.session_state.video_path, "rb") as file:
                    st.download_button(
                        label="‚¨áÔ∏è Download do V√≠deo",
                        data=file,
                        file_name=Path(st.session_state.video_path).name,
                        mime="video/mp4"
                    )

        else:
            st.info("Gere as imagens primeiro antes de criar o v√≠deo!")

    # Tab 4: Documenta√ß√£o
    with tab4:
        st.header("Documenta√ß√£o T√©cnica")

        st.markdown("""
        ## Pipeline de Gera√ß√£o

        ### 1. Gera√ß√£o de Imagens
        - **Modelo**: Stable Diffusion (Hugging Face Diffusers)
        - **T√©cnica**: Text-to-Image com controle de seed
        - **Estrat√©gia de Consist√™ncia**: Seeds sequenciais a partir de uma seed base
        - **Par√¢metros Principais**:
          - Guidance Scale: controla ader√™ncia ao prompt
          - Inference Steps: qualidade da gera√ß√£o
          - Negative Prompt: evita caracter√≠sticas indesejadas

        ### 2. Gera√ß√£o de V√≠deo
        - **T√©cnica**: Interpola√ß√£o linear entre frames (cross-dissolve)
        - **Biblioteca**: OpenCV
        - **Processo**:
          1. Cada imagem √© mantida por N frames (definido por FPS √ó dura√ß√£o)
          2. Transi√ß√µes suaves entre imagens usando cv2.addWeighted
          3. Loop opcional para criar anima√ß√£o cont√≠nua

        ### 3. Ferramentas Utilizadas
        - **diffusers**: Gera√ß√£o de imagens com Stable Diffusion
        - **transformers**: Modelos de linguagem para processamento de prompts
        - **torch**: Backend de deep learning
        - **opencv-python**: Processamento de v√≠deo
        - **streamlit**: Interface web interativa

        ### 4. Desafios e Solu√ß√µes

        #### Consist√™ncia Visual
        - **Desafio**: Manter identidade do personagem entre imagens
        - **Solu√ß√£o**: Uso de seeds sequenciais e prompt detalhado

        #### Coer√™ncia Temporal
        - **Desafio**: Transi√ß√µes suaves no v√≠deo
        - **Solu√ß√£o**: Interpola√ß√£o linear entre frames

        #### Limita√ß√µes
        - Modelos locais requerem GPU com boa mem√≥ria
        - Gera√ß√£o pode ser lenta em hardware limitado
        - Consist√™ncia n√£o √© perfeita (varia√ß√µes podem ocorrer)

        ### 5. Melhorias Futuras
        - Implementar ControlNet para maior controle
        - Adicionar motion transfer com MediaPipe
        - Integrar modelos text-to-video (Gen-2, Pika)
        - Adicionar efeitos de zoom, pan, rotate
        """)

        # Exportar documenta√ß√£o completa
        if st.session_state.generation_params and st.session_state.video_params:
            st.subheader("Exportar Documenta√ß√£o Completa")

            doc_data = {
                "projeto": "Personagem Generativo e Anima√ß√£o Curta",
                "timestamp": datetime.now().isoformat(),
                "gera√ß√£o_imagens": st.session_state.generation_params,
                "gera√ß√£o_v√≠deo": st.session_state.video_params,
                "pipeline": {
                    "etapa_1": "Gera√ß√£o de imagens com Stable Diffusion",
                    "etapa_2": "Cria√ß√£o de v√≠deo com interpola√ß√£o de frames",
                    "ferramentas": ["Stable Diffusion", "OpenCV", "Streamlit"],
                }
            }

            doc_json = json.dumps(doc_data, indent=2, ensure_ascii=False)

            st.download_button(
                label="üìÑ Download Documenta√ß√£o (JSON)",
                data=doc_json,
                file_name=f"documentacao_tecnica_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )


if __name__ == "__main__":
    main()
