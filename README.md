# Personagem Generativo e Anima√ß√£o Curta

Pipeline completo de IA Generativa para cria√ß√£o de personagens visuais consistentes e gera√ß√£o de v√≠deo animado.

## Descri√ß√£o do Projeto

Este projeto implementa um sistema de gera√ß√£o de personagens usando Stable Diffusion e cria√ß√£o de v√≠deos animados a partir das imagens geradas. O objetivo √© criar:

- **M√≠nimo 10 imagens** do personagem com consist√™ncia visual
- **V√≠deo animado** de 5-20 segundos preservando a identidade do personagem
- **Documenta√ß√£o t√©cnica** completa do pipeline

## Estrutura do Projeto

```
projeto_PersonagemAnimado/
‚îú‚îÄ‚îÄ app.py                      # Interface Streamlit principal
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ image_generator.py      # M√≥dulo de gera√ß√£o de imagens
‚îÇ   ‚îî‚îÄ‚îÄ video_generator.py      # M√≥dulo de gera√ß√£o de v√≠deo
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ images/                 # Imagens geradas
‚îÇ   ‚îî‚îÄ‚îÄ videos/                 # V√≠deos gerados
‚îú‚îÄ‚îÄ Docs/
‚îÇ   ‚îî‚îÄ‚îÄ Projeto da Disciplina.pdf
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

## Instala√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- GPU com CUDA (recomendado) ou CPU (mais lento)
- 8GB+ de RAM (16GB recomendado)
- Espa√ßo em disco: ~5GB para modelos

### Passo a Passo

1. **Clone ou baixe o projeto**

```bash
cd projeto_PersonagemAnimado
```

2. **Crie um ambiente virtual**

```bash
python -m venv .venv
```

3. **Ative o ambiente virtual**

Windows:

```bash
.venv\Scripts\activate
```

Linux/Mac:

```bash
source .venv/bin/activate
```

4. **Instale as depend√™ncias**

```bash
pip install -r requirements.txt
```

**Nota**: A instala√ß√£o pode levar alguns minutos, especialmente o PyTorch.

### Instala√ß√£o do PyTorch com CUDA (Opcional mas Recomendado)

Se voc√™ tem uma GPU NVIDIA, instale a vers√£o CUDA do PyTorch:

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## Como Usar

### 1. Executar a Interface Streamlit

```bash
streamlit run app.py
```

O aplicativo abrir√° no navegador em `http://localhost:8501`

### 2. Gerar Imagens do Personagem

1. Na aba **"Gera√ß√£o"**, descreva seu personagem no campo de prompt
2. Ajuste os par√¢metros na barra lateral (opcional):
   - N√∫mero de imagens (m√≠nimo 10)
   - Seed (para reprodutibilidade)
   - Guidance Scale (7-15 recomendado)
   - Passos de Infer√™ncia (50 √© bom equil√≠brio)
3. Clique em **"Gerar Imagens"**
4. Aguarde a gera√ß√£o (pode levar 5-15 minutos dependendo do hardware)

### 3. Visualizar Imagens

1. V√° para a aba **"Imagens"**
2. Visualize todas as imagens geradas em grade
3. Confira os par√¢metros de gera√ß√£o

### 4. Criar V√≠deo Animado

1. Na aba **"V√≠deo"**, escolha o m√©todo:
   - **Transi√ß√µes (OpenCV)**: Para m√∫ltiplas imagens com fade (funciona em qualquer hardware)
   - **IA - Stable Video Diffusion**: Para animar uma imagem com movimento real (requer GPU)
2. Ajuste os par√¢metros conforme o m√©todo escolhido:
   - **OpenCV**: FPS, dura√ß√£o por imagem, frames de transi√ß√£o, loop
   - **SVD**: Frames (15-25), FPS (3-7), resolu√ß√£o, passos de infer√™ncia
3. Se usar SVD, escolha qual imagem animar (m√©todo anima uma por vez)
4. Clique em **"Gerar V√≠deo"**
5. Aguarde a cria√ß√£o:
   - OpenCV: ~30 segundos
   - SVD: 2-3 minutos (primeira vez baixa modelo)
6. Assista ao v√≠deo e fa√ßa download se desejar

### 5. Exportar Documenta√ß√£o

1. V√° para a aba **"Documenta√ß√£o"**
2. Leia sobre o pipeline t√©cnico
3. Clique em **"Download Documenta√ß√£o"** para exportar metadados em JSON

## Uso via Scripts Python

### Gerar Imagens Diretamente

```python
from src.image_generator import ImageGenerator

# Criar gerador
generator = ImageGenerator()

# Gerar imagens
images = generator.generate_images(
    prompt="A cute cartoon robot, blue and white colors",
    num_images=10,
    seed=42,
    guidance_scale=7.5,
    num_inference_steps=50
)
```

### Criar V√≠deo Diretamente

```python
from src.video_generator import VideoGenerator
from glob import glob

# Criar gerador de v√≠deo
video_gen = VideoGenerator()

# Buscar imagens
image_files = sorted(glob("outputs/images/*/character_*.png"))

# M√©todo 1: Criar v√≠deo com transi√ß√µes (OpenCV)
video_path = video_gen.create_video_from_images(
    images=image_files,
    fps=3,
    duration_per_image=1.5,
    transition_frames=15,
    add_loop=True
)

# M√©todo 2: Animar imagem com SVD (requer GPU)
from PIL import Image
image = Image.open("outputs/images/character_001.png")
video_path = video_gen.animate_image_svd(
    image=image,
    output_path="outputs/videos/svd_animation.mp4",
    num_frames=20,  # Para ~5 segundos
    fps=4,
    resolution=(512, 320),  # Otimizado para 8GB VRAM
    num_inference_steps=25
)
```

## Pipeline T√©cnico

### Gera√ß√£o de Imagens

**Modelo**: Stable Diffusion v1.5 (Hugging Face Diffusers)

**Estrat√©gia de Consist√™ncia**:

- Seeds sequenciais a partir de uma seed base
- Prompt detalhado e consistente
- Negative prompt para evitar artefatos

**Par√¢metros Principais**:

- `guidance_scale`: Controla ader√™ncia ao prompt (7-15)
- `num_inference_steps`: Qualidade da gera√ß√£o (30-100)
- `seed`: Reprodutibilidade

### Gera√ß√£o de V√≠deo

O sistema oferece **duas abordagens** para cria√ß√£o de v√≠deo:

#### 1. M√©todo de Transi√ß√µes (OpenCV)

**Biblioteca**: OpenCV (cv2)  
**T√©cnica**: Interpola√ß√£o linear entre frames (cross-dissolve)  
**Requisitos**: Qualquer hardware (CPU ou GPU)

**Processo**:
1. Cada imagem √© mantida por N frames est√°ticos
2. Transi√ß√µes suaves usando `cv2.addWeighted`
3. Loop opcional para anima√ß√£o cont√≠nua

**Vantagens**:
- ‚úÖ Funciona em CPU ou GPU
- ‚úÖ R√°pido (~30 segundos)
- ‚úÖ N√£o requer download adicional de modelos

**Limita√ß√µes**:
- ‚ö†Ô∏è Apenas transi√ß√µes (fade), n√£o movimento real
- ‚ö†Ô∏è Resultado √© mais "slideshow" que anima√ß√£o

#### 2. M√©todo Stable Video Diffusion (SVD) üÜï

**Modelo**: Stable Video Diffusion XT (Hugging Face)  
**T√©cnica**: IA generativa para animar imagens  
**Requisitos**: GPU CUDA com 8GB+ VRAM

**Processo**:
1. Anima uma √∫nica imagem com movimento realista
2. Gera v√≠deo de 5-10 segundos automaticamente
3. Preserva identidade visual da imagem

**Vantagens**:
- ‚úÖ Movimento real gerado por IA
- ‚úÖ V√≠deos mais naturais e din√¢micos
- ‚úÖ Preserva identidade visual perfeitamente

**Limita√ß√µes**:
- ‚ö†Ô∏è Requer GPU CUDA
- ‚ö†Ô∏è Primeira execu√ß√£o baixa modelo grande (~5GB)
- ‚ö†Ô∏è Processamento mais lento (2-3 minutos)

**Otimiza√ß√µes Implementadas**:
- FP16 (metade da mem√≥ria)
- CPU Offloading (move partes para RAM)
- Attention Slicing m√°ximo
- Resolu√ß√£o otimizada (512x320)
- Suporta GPUs com apenas 8GB VRAM

## Ferramentas Utilizadas

- **diffusers**: Gera√ß√£o de imagens com Stable Diffusion
- **transformers**: Modelos de linguagem
- **torch**: Backend de deep learning
- **opencv-python**: Processamento de v√≠deo
- **streamlit**: Interface web
- **PIL/Pillow**: Manipula√ß√£o de imagens

## Desafios e Limita√ß√µes

### Consist√™ncia Visual

- **Desafio**: Manter identidade entre gera√ß√µes
- **Solu√ß√£o Atual**: Seeds sequenciais
- **Melhoria Futura**: ControlNet com pose reference

### Coer√™ncia Temporal

- **Desafio**: Transi√ß√µes suaves e movimento real
- **Solu√ß√£o Atual**: 
  - M√©todo 1: Interpola√ß√£o linear (transi√ß√µes)
  - M√©todo 2: Stable Video Diffusion (movimento real) ‚úÖ **IMPLEMENTADO**
- **Melhoria Futura**: Motion transfer, integra√ß√£o com outros modelos text-to-video

### Recursos Computacionais

- **Gera√ß√£o de imagens**: Requer GPU para velocidade adequada (CPU √© muito lento)
- **V√≠deo OpenCV**: Funciona em qualquer hardware (CPU ou GPU)
- **V√≠deo SVD**: Requer GPU CUDA com 8GB+ VRAM (otimizado para 8GB)
- **Espa√ßo em disco**: 
  - Stable Diffusion: ~5GB
  - SVD: +5GB (baixado na primeira execu√ß√£o)
  - Total: ~10GB

## Melhorias Futuras

1. ‚úÖ **Stable Video Diffusion**: Implementado - anima√ß√£o realista com IA
2. **ControlNet**: Maior controle sobre pose e estrutura
3. **Motion Transfer**: MediaPipe Pose para anima√ß√µes mais naturais
4. **Text-to-Video**: Integra√ß√£o com outros modelos (Gen-2, Pika Labs, Runway)
5. **Efeitos**: Zoom, pan, rotate nas transi√ß√µes
6. **API Integration**: Suporte para APIs cloud (Stability AI, Replicate)
7. **SVD Multi-Image**: Animar m√∫ltiplas imagens sequencialmente

## Requisitos do Projeto (Checklist)

- [x] M√≠nimo 10 imagens do personagem
- [x] V√≠deo animado de 5-20 segundos
- [x] Pipeline de gera√ß√£o estruturado
- [x] Controle de par√¢metros (seeds, guidance, prompts)
- [x] Consist√™ncia visual entre imagens
- [x] Preserva√ß√£o de identidade no v√≠deo
- [x] Documenta√ß√£o t√©cnica
- [x] Scripts e c√≥digos organizados
- [x] Metadados salvos (JSON)

## Troubleshooting

### Erro: "CUDA out of memory"

- Reduza o tamanho das imagens (width/height)
- Reduza batch size (gere menos imagens por vez)
- Use `use_fp16=True` para economizar mem√≥ria
- Feche outros programas que usam GPU

### Erro: "Model not found"

- Verifique conex√£o com internet (primeiro uso baixa modelo)
- Aguarde download completar (~5GB)
- Verifique espa√ßo em disco

### Gera√ß√£o muito lenta

- Use GPU em vez de CPU
- Reduza `num_inference_steps`
- Considere usar APIs cloud

## Autores

**Vanthuir Maia** - vanmaiasf@gmail.com
**Rodrigo Santana** - rodrigoalisson33@gmail.com

## Informa√ß√µes Acad√™micas

**Institui√ß√£o**: Universidade de Pernambuco (UPE)
**Programa**: Resid√™ncia em IA Generativa
**Disciplina**: IA Generativa para M√≠dia Visual

## Licen√ßa

Este projeto √© para fins educacionais.
